{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación en MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset MNIST ([link](http://yann.lecun.com/exdb/mnist/)) es un **estándar** para evauar modelos de clasificación. \n",
    "\n",
    "Está compuesto por imagenes grises de 28x28 pixeles donde cada imagen posee un digito manuscrito (del 0 al 9) centrado en la misma.\n",
    "\n",
    "![img](https://tensorflow.rstudio.com/tensorflow/articles/images/MNIST.png)\n",
    "\n",
    "Este dataset es famoso debido a su gran cantidad de *samples* y a la capacidad de tener buena *performance* con modelos relativamente simples. Es muy usual que MNIST aparezca como dataset de prueba en tutoriales y/o cursos de Machine Learning y Deep Learning.\n",
    "\n",
    "Hoy en dia es un problema más que resuelto. Existen modelos que ya han conseguido un error < 0.2% en el set de *test*.\n",
    "\n",
    "Este notebook va a desarrollar una implementacion (en Tensorflow) de una red neuronal de capas totalmente conectadas para resolver el problema (tambien conocidas como *\"Fully Connected Networks\"* o *\"Dense Networks\"*). Cada paso va a estar detallado y explicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente comando importa las librerias requeridas por el resto del programa. Detallamos las mas importantes:\n",
    "\n",
    "* **numpy**: para el manejo en CPU de los tensores (vectores multidimensionales)\n",
    "* **matplotlib**: para graficar en el notebook\n",
    "* **tensorflow**: para construir y entrenar la red neuronal\n",
    "* **utils**: modulo propio presente en `utils.py` con funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a cargar el dataset. Para eso, usamos una funcion auxiliar del archivo `utils.py` que se va a encargar de realizar esto.\n",
    "\n",
    "Esta funcion retorna un 4-upla donde cada elemento es un *numpy array* y además:\n",
    "\n",
    "* *pics_train*: contiene las imagenes de *training*\n",
    "* *labels_train*: contiene los labels (el valor real, tambien llamado *ground truth*) de cada una de las iamgenes de *training*\n",
    "* *pics_test*: contiene las imagenes de *testing*. Estas imagenes solo se van a utilizar al final para medir performance, pero **no para entrenar**.\n",
    "* *labels_test*: contiene los labels de cada una de las imagenes de *testing*\n",
    "\n",
    "Estos objetos van a ser nuestros **datos** para el aprendizaje supervisado. En los objetos *\"pics\"* tenemos nuestros *inputs* y en los objetos *\"labels\"* tenemos nuestros *outputs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train, labels_train, pics_test, labels_test = utils.load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las dimensiones de cada uno de los *numpy arrays*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data:\")\n",
    "print(pics_train.shape)\n",
    "print(labels_train.shape)\n",
    "print()\n",
    "print(\"Test data:\")\n",
    "print(pics_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 55000 imagenes de *training* donde cada una es un tensor de 28x28x1 (que representa el valor del gris, en la ultima dimensión, de cada pixel en la imagen). Nota: si bien podría ser 28x28 (es decir, sin el \"x1\" del final), se acostumbra en la práctica a dejar siempre el formato NWHC (Number - Width - Height - Channels).\n",
    "\n",
    "A la vez, hay 55000 vectores de 10 que son los *labels* del *training*. El formato del label sigue el patrón *\"One-hot encoding\"*, en el cual cada valor de verdad se representa como una distribucion de probabilidades por todas las posibles clases. Por ejemplo, para representar el *label* '3', el vector seria [0 0 0 1 0 0 0 0 0 0 0] (osea, todos las clases en 0, menos la correspondiente, en 1). De nuevo, este formato es el estandar para representar los *labels* en un problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando algunas imagenes de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando una de las funciones auxiliares de `utils.py`, podemos observar algunas imagenes acompañadas de su correspondiente *label*, es decir, de su valor de verdad (o *ground truth*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_random_mnist(pics_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como se representa el valor del pixel en las imagenes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos antes, son imagenes en escala de grises (esto significa que tienen un solo canal). Ahora bien, veamos si los valores estan representados entre [0, 255] o entre [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(pics_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto quiere decir que los valores están normalizados! Es decir, valores entre 0 y 1. Esto es muy usual en Machine Learning, pues evita problemas numéricos y puede ayudar a la convergencia en la búsqueda de la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos algunas variables importantes que nos van a servir luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, H, W, _ = pics_train.shape\n",
    "F = H * W\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) La Arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura, como se dijo antes, va a ser una red de capas densas unicamente (o *fully-connected*):\n",
    "\n",
    "![img](https://chsasank.github.io/assets/images/crash_course/mnist_net.png)\n",
    "\n",
    "La entrada de la red (el *input*) va a ser un vector aplanado de tamaño 28x28. Corresponde a aplanar los valores de cada pixel en un unico vector de 1 dimension. El *output* de la red van a ser 10 valores correspondientes a los *scores* de cada clase.\n",
    "\n",
    "El flujo sería el siguiente:\n",
    "\n",
    "1. Tomamos una imagen de 28x28.\n",
    "2. Se aplana en un vector de una dimension.\n",
    "3. Se introduce en la red y fluye hacia la capa de salida.\n",
    "4. La capa de salida va a ser un vector de 10 elementos, donde cada uno representa un *score* de que esa imagen pertenezca a esa clase. Cuanto mayor sea el *score*, buscamos que sea más probable que la imagen pertenezca a esa clase (es decir, que sea ESE digito). Cuando la red esté entrenada, la clase (o el dígito) correcto va a ser aquel que tengo mayor *score*.\n",
    "\n",
    "No vamos a entrar en profundidad en los detalles de implementacion de Tensorflow. Para aquello, puede recurrir a los tutoriales oficiales [aqui](https://www.tensorflow.org/tutorials/), muy simples de seguir y entender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_architecture():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, 1], name=\"x\")\n",
    "    y = tf.placeholder(tf.uint8, shape=[None, NUM_CLASSES], name=\"y\")\n",
    "    \n",
    "    init = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    out = tf.contrib.layers.flatten(x)\n",
    "\n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=NUM_CLASSES, kernel_initializer=init, name=\"out\")\n",
    "    \n",
    "    return x, y, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) La función de costo (*loss*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion de costo para este problema va a ser la entropía cruzada aplicada a la funcion softmax sobre la capa de salida. Expliquemos un poco esto:\n",
    "\n",
    "En primer lugar, se computa la funcion softmax sobre la capa de salida (que son los *scores* de las clases). Esta funcion tiene la siguiente pinta:\n",
    "\n",
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "Esta funcion mapea los *scores* a una distribucion de probabilidad, intensificando el valor del maximo (por ejemplo, si los scores hubieran sido [1.3, -0.2, 5.2], la funcion daria un vector ~[0.0197, 0.0044, 0.976]. Ahora, el *output* de la red está en terminos de probabilidad, al igual que el *ground truth*! (acuerdense que está en formato *One-hot encoding*).\n",
    "\n",
    "Gracias a esto, definimos la entropia cruzada, que es una forma de relacionar dos distribuciones de probabilidad:\n",
    "\n",
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "En resumen, cuando la probabilidad de la clase correcta en el *output* sea relativamente baja, la entropia cruzada va a ser altisima. Cuando sea alta, la entropia va a ser baja. Vamos a intentar minimizar la *loss* (que es la entropia cruzada luego del softmax), para buscar este ultimo comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(y, out):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out, name=\"mean_loss\")\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La *accuracy* mide el porcentaje de eficacia entre los *labels* y el *output* de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accuracy(y, out):\n",
    "    pred = tf.argmax(out, axis=-1)\n",
    "    gt = tf.argmax(y, axis=-1)\n",
    "    \n",
    "    matches = tf.equal(pred, gt)\n",
    "    \n",
    "    return tf.reduce_mean(tf.cast(matches, tf.float32), name=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) La elección del minimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estar utilizando Gradiente Descendente Estocástico, comúnmente conocido como *Stochastic Gradient Descent* (SGD) con un *learning rate* de 10e-3.\n",
    "\n",
    "Para más información acerca de los minimizadores, leer el siguiente excelente blog [aqui](http://ruder.io/optimizing-gradient-descent/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainer(loss):\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    return opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones complementarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones son complementarias y no revisten de mayor importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_scalars(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_images(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.image(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente funcion junta todos los pasos anteriores para definir el modelo final. Esta funcion es la encargada de cargar el grafo en Tensorflow para luego correr la optimizacion.\n",
    "\n",
    "La funcion retorna aquellos nodos del grafo necesarios para ser corridos luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    x, y, out = load_architecture()\n",
    "    loss = load_loss(y, out)\n",
    "    acc = load_accuracy(y, out)\n",
    "    upd = load_trainer(loss)\n",
    "    \n",
    "    register_scalars({\"info_loss\": loss, \"info_acc\": acc})\n",
    "    register_images({\"input\": x})\n",
    "\n",
    "    info = tf.summary.merge_all()\n",
    "    \n",
    "    return x, y, out, loss, acc, upd, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow requiere:\n",
    "\n",
    "1. Definir el grafo computacional (lo que hicimos antes)\n",
    "2. Correr el grafo a traves de una `Session`.\n",
    "\n",
    "A continuacion, definimos la sesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session():\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, definimos una funcion que encapsula todo el entrenamiento de la red, es decir, la optimizacion de la funcion de *loss* definida previamente.\n",
    "\n",
    "Esta funcion recibe la sesion, el modelo, la data, la cantidad de epocas, el tamaño del *batch* (para SGD) y los *writers*, que sirven para hacer uso de la herramienta de visualizacion *tensorboard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, model, pics_train, labels_train, pics_val, labels_val, epochs, batch_size, train_writer, val_writer):\n",
    "    N, _, _, _ = pics_train.shape\n",
    "    idxs = np.arange(N)\n",
    "    \n",
    "    x, y, out, loss, acc, upd, info = model\n",
    "        \n",
    "    i=0\n",
    "\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        np.random.shuffle(idxs)\n",
    "        pics_train = pics_train[idxs]\n",
    "        labels_train = labels_train[idxs]\n",
    "\n",
    "        for b in range(0, N, batch_size):\n",
    "            X_batch = pics_train[b:b+batch_size]\n",
    "            Y_batch = labels_train[b:b+batch_size]\n",
    "\n",
    "            if X_batch.shape[0] < BATCH_SIZE:\n",
    "                break\n",
    "\n",
    "            graph_info, _ = sess.run([info, upd], feed_dict={x: X_batch, y: Y_batch})\n",
    "            train_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            graph_info, = sess.run([info], feed_dict={x: pics_val, y: labels_val})\n",
    "            val_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, definimos una funcion que nos va a permitir probar el modelo entrenado. Esta funcion simplemente ejecuta la red con las imagenes que se proveen como parametro. Retorna las inferencias (es decir, las clases \"ganadoras\") para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imgs, sess, model):\n",
    "    x, y, out, loss, acc, upd, info = model\n",
    "\n",
    "    N, H, W, _ = imgs.shape\n",
    "    fig=plt.figure(figsize=(10, 10))\n",
    "    columns = 3\n",
    "    rows = 3\n",
    "    for i in range(1, columns*rows +1):\n",
    "        idx = np.random.choice(range(N)) \n",
    "        img = imgs[idx].reshape((1, H, W, 1))\n",
    "        graph_out, = sess.run([out], feed_dict={x: img})\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "        plt.title(np.argmax(np.squeeze(graph_out)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corriendo el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos las funciones definidas anteriormente y carguemos el modelo, para luego crear una sesión sobre ese modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "sess = load_session()\n",
    "print(\"Trainable parameters: {}\".format(trainable_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, corramos el entrenamiento. El siguiente paso va a llevar un tiempo... (dependiendo tambien si estan corriendo en GPU o CPU). Paciencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 70\n",
    "BATCH_SIZE = 64\n",
    "LOGS_DIR = \"logs\"\n",
    "\n",
    "t_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all\", \"train\"), graph=sess.graph)\n",
    "v_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all\", \"val\"), graph=sess.graph)\n",
    "\n",
    "train(sess, model, pics_train, labels_train, pics_test, labels_test, EPOCHS, BATCH_SIZE, t_writer, v_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la carpeta `logs` van a poder tener informacion util para analizar el proceso de entrenamiento. Para verla, se necesita levantar `tensorboard`. Para esto, ir a la consola y ejecutar:\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir ./logs\n",
    "```\n",
    "\n",
    "Se les va a abrir un *tab* en el navegador donde van a poder ver los graficos de entrenamiento en funcion de las épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando inferencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegamos a la parte mejor parte: **usar el modelo**. Veamos algunas predicciones sobre el set de *training*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_train, sess, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene mucho sentido que tenga una *performance* perfecta pues la red esta entrenada para identificar estos ejemplos puntuales. Medir la *performance* en el dataset de *training* no está aceptado como práctica, pues no es un indicador \"honesto\". \n",
    "\n",
    "Corramos la red para los ejemplos que la red no vió antes, es decir, los de *testing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_test, sess, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midamos el *accuracy* final de nuestro modelo sobre todo el set de *testing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, out, loss, acc, upd, info = model\n",
    "\n",
    "N, H, W, _ = pics_test.shape\n",
    "graph_out, = sess.run([acc], feed_dict={x: pics_test, y: labels_test})\n",
    "print(\"Overall accuracy: {0:.2f}%\".format(100 * graph_out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-env",
   "language": "python",
   "name": "workshop-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
