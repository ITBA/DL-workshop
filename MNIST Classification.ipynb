{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train, labels_train, pics_test, labels_test = utils.load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data:\")\n",
    "print(pics_train.shape)\n",
    "print(labels_train.shape)\n",
    "print()\n",
    "print(\"Test data:\")\n",
    "print(pics_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_random_mnist(pics_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(pics_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, H, W, _ = pics_train.shape\n",
    "F = H * W\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_architecture():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, 1], name=\"x\")\n",
    "    y = tf.placeholder(tf.uint8, shape=[None, NUM_CLASSES], name=\"y\")\n",
    "    \n",
    "    init = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    out = tf.contrib.layers.flatten(x)\n",
    "\n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=NUM_CLASSES, kernel_initializer=init)\n",
    "    \n",
    "    return x, y, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(y, out):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out, name=\"mean_loss\")\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accuracy(y, out):\n",
    "    pred = tf.argmax(out, axis=-1)\n",
    "    gt = tf.argmax(y, axis=-1)\n",
    "    \n",
    "    matches = tf.equal(pred, gt)\n",
    "    \n",
    "    return tf.reduce_mean(tf.cast(matches, tf.float32), name=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainer(loss):\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    return opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_scalars(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_images(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.image(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    x, y, out = load_architecture()\n",
    "    loss = load_loss(y, out)\n",
    "    acc = load_accuracy(y, out)\n",
    "    upd = load_trainer(loss)\n",
    "    \n",
    "    register_scalars({\"info_loss\": loss, \"info_acc\": acc})\n",
    "    register_images({\"input\": x})\n",
    "\n",
    "    info = tf.summary.merge_all()\n",
    "    \n",
    "    return x, y, out, loss, acc, upd, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session():\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, model, pics_train, labels_train, pics_val, labels_val, epochs, batch_size, train_writer, val_writer):\n",
    "    N, _, _, _ = pics_train.shape\n",
    "    idxs = np.arange(N)\n",
    "    \n",
    "    x, y, out, loss, acc, upd, info = model\n",
    "        \n",
    "    i=0\n",
    "\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        np.random.shuffle(idxs)\n",
    "        pics_train = pics_train[idxs]\n",
    "        labels_train = labels_train[idxs]\n",
    "\n",
    "        for b in range(0, N, batch_size):\n",
    "            X_batch = pics_train[b:b+batch_size]\n",
    "            Y_batch = labels_train[b:b+batch_size]\n",
    "\n",
    "            if X_batch.shape[0] < BATCH_SIZE:\n",
    "                break\n",
    "\n",
    "            graph_info, _ = sess.run([info, upd], feed_dict={x: X_batch, y: Y_batch})\n",
    "            train_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            graph_info, = sess.run([info], feed_dict={x: pics_val, y: labels_val})\n",
    "            val_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imgs, model):\n",
    "    x, y, out, loss, acc, upd, info = model\n",
    "\n",
    "    N, H, W, _ = imgs.shape\n",
    "    fig=plt.figure(figsize=(10, 10))\n",
    "    columns = 3\n",
    "    rows = 3\n",
    "    for i in range(1, columns*rows +1):\n",
    "        idx = np.random.choice(range(N)) \n",
    "        img = imgs[idx].reshape((1, H, W, 1))\n",
    "        graph_out, = sess.run([out], feed_dict={x: img})\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "        plt.title(np.argmax(np.squeeze(graph_out)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "sess = load_session()\n",
    "print(\"Trainable parameters: {}\".format(trainable_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 70\n",
    "BATCH_SIZE = 64\n",
    "LOGS_DIR = \"logs\"\n",
    "\n",
    "t_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all\", \"train\"), graph=sess.graph)\n",
    "v_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all\", \"val\"), graph=sess.graph)\n",
    "\n",
    "train(sess, model, pics_train, labels_train, pics_test, labels_test, EPOCHS, BATCH_SIZE, t_writer, v_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_train, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-env",
   "language": "python",
   "name": "workshop-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
